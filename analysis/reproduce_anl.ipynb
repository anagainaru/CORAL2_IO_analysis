{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "import csv\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_name = \"nwchem\"\n",
    "postfix_name = \"\"\n",
    "darshan_file = \"../%s/darshan/%s%s\" %(application_name, application_name, postfix_name)\n",
    "feature_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IOType</th>\n",
       "      <th>Rank</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Counter</th>\n",
       "      <th>Value</th>\n",
       "      <th>FileName</th>\n",
       "      <th>MountPt</th>\n",
       "      <th>FSType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>1828374797521024576</td>\n",
       "      <td>POSIX_OPENS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>/gpfs/alpine</td>\n",
       "      <td>gpfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>1828374797521024576</td>\n",
       "      <td>POSIX_FILENOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>/gpfs/alpine</td>\n",
       "      <td>gpfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>1828374797521024576</td>\n",
       "      <td>POSIX_DUPS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>/gpfs/alpine</td>\n",
       "      <td>gpfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>1828374797521024576</td>\n",
       "      <td>POSIX_READS</td>\n",
       "      <td>9.0</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>/gpfs/alpine</td>\n",
       "      <td>gpfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>1828374797521024576</td>\n",
       "      <td>POSIX_WRITES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>/gpfs/alpine</td>\n",
       "      <td>gpfs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IOType  Rank             RecordID        Counter  Value  \\\n",
       "0  POSIX     0  1828374797521024576    POSIX_OPENS    2.0   \n",
       "1  POSIX     0  1828374797521024576  POSIX_FILENOS    0.0   \n",
       "2  POSIX     0  1828374797521024576     POSIX_DUPS    0.0   \n",
       "3  POSIX     0  1828374797521024576    POSIX_READS    9.0   \n",
       "4  POSIX     0  1828374797521024576   POSIX_WRITES    0.0   \n",
       "\n",
       "                                            FileName       MountPt FSType  \n",
       "0  /gpfs/alpine/csc143/proj-shared/againaru/nwche...  /gpfs/alpine   gpfs  \n",
       "1  /gpfs/alpine/csc143/proj-shared/againaru/nwche...  /gpfs/alpine   gpfs  \n",
       "2  /gpfs/alpine/csc143/proj-shared/againaru/nwche...  /gpfs/alpine   gpfs  \n",
       "3  /gpfs/alpine/csc143/proj-shared/againaru/nwche...  /gpfs/alpine   gpfs  \n",
       "4  /gpfs/alpine/csc143/proj-shared/againaru/nwche...  /gpfs/alpine   gpfs  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregaed log information\n",
    "df_agg = pd.read_csv(darshan_file + \".log\", delimiter='\\t', comment='#',\n",
    "                     names=['IOType', 'Rank', 'RecordID', 'Counter', 'Value',\n",
    "                            'FileName', 'MountPt', 'FSType'])\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata available for ['darshan log version', 'compression method', 'exe', 'uid', 'jobid', 'start_time', 'start_time_asci', 'end_time', 'end_time_asci', 'nprocs', 'run time', 'metadata', 'header', 'job data', 'record table', 'POSIX module', 'STDIO module', 'DXT_POSIX module', 'mount entry', 'description of columns', '<module>', '<rank>', '<record id>', '<counter name> and <counter value>', '<file name>', '<mount pt>', '<fs type>', 'description of POSIX counters', 'POSIX_*', 'POSIX_RENAME_SOURCES/TARGETS', 'POSIX_RENAMED_FROM', 'POSIX_MODE', 'POSIX_BYTES_*', 'POSIX_MAX_BYTE_*', 'POSIX_CONSEC_*', 'POSIX_SEQ_*', 'POSIX_RW_SWITCHES', 'POSIX_*_ALIGNMENT', 'POSIX_*_NOT_ALIGNED', 'POSIX_MAX_*_TIME_SIZE', 'POSIX_SIZE_*_*', 'POSIX_STRIDE*_STRIDE', 'POSIX_STRIDE*_COUNT', 'POSIX_ACCESS*_ACCESS', 'POSIX_ACCESS*_COUNT', 'POSIX_*_RANK', 'POSIX_*_RANK_BYTES', 'POSIX_F_*_START_TIMESTAMP', 'POSIX_F_*_END_TIMESTAMP', 'POSIX_F_READ/WRITE/META_TIME', 'POSIX_F_MAX_*_TIME', 'POSIX_F_*_RANK_TIME', 'POSIX_F_VARIANCE_RANK_*', 'WARNING', '- Affected counters include']\n"
     ]
    }
   ],
   "source": [
    "# Metadata information\n",
    "def read_metadata(filename):\n",
    "    metadata = {}\n",
    "    inf = open(filename)\n",
    "    for line in inf:\n",
    "        # ignore blank lines\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        # stop when the header section is finished\n",
    "        if line[0] != \"#\":\n",
    "            break\n",
    "        delimiter = line.find(\":\")\n",
    "        if delimiter == -1:\n",
    "            continue\n",
    "        key = line[2 : delimiter].lstrip().rstrip()\n",
    "        value = line[delimiter + 1 : -1].lstrip().rstrip()\n",
    "        if key not in metadata:\n",
    "            metadata[key] = []\n",
    "        metadata[key].append(value)\n",
    "    inf.close()\n",
    "    return metadata\n",
    "\n",
    "metadata = read_metadata(darshan_file + \".log\")\n",
    "print(\"Metadata available for %s\" %([i for i in metadata]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Rank</th>\n",
       "      <th>IOType</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Length</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>File</th>\n",
       "      <th>Offset_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>read</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X_POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>read</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X_POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3425</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X_POSIX</td>\n",
       "      <td>0</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>/gpfs/alpine/csc143/proj-shared/againaru/nwche...</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Module  Rank IOType  Segment  Offset  Length   Start     End  \\\n",
       "0    X_POSIX     0   read        0       0     269  0.0475  0.0475   \n",
       "3    X_POSIX     0   read        3       0     269  0.1280  0.1280   \n",
       "6    X_POSIX     0   read        6       0     269  0.3202  0.3202   \n",
       "9    X_POSIX     0   read        0       0    3425  0.2738  0.2738   \n",
       "11   X_POSIX     0   read        0       0    8192  0.4403  0.4420   \n",
       "\n",
       "                                                 File  Offset_end  \n",
       "0   /gpfs/alpine/csc143/proj-shared/againaru/nwche...         269  \n",
       "3   /gpfs/alpine/csc143/proj-shared/againaru/nwche...         269  \n",
       "6   /gpfs/alpine/csc143/proj-shared/againaru/nwche...         269  \n",
       "9   /gpfs/alpine/csc143/proj-shared/againaru/nwche...        3425  \n",
       "11  /gpfs/alpine/csc143/proj-shared/againaru/nwche...        8192  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DXT information\n",
    "\n",
    "def get_accessed_files(file):\n",
    "    inf = open(file)\n",
    "    file_list = []\n",
    "    cfile = 0\n",
    "    for line in inf:\n",
    "        if \"DXT, file_id:\" in line:\n",
    "            idx = line.find(\"file_name\")\n",
    "            cfile = line[idx+11:-1]\n",
    "        if \"DXT, write_count:\" in line:\n",
    "            access_cnt = sum([int(i) for i in re.findall(r'\\d+', line)])\n",
    "            file_list += [cfile] * access_cnt\n",
    "    inf.close()\n",
    "    return file_list\n",
    "\n",
    "\n",
    "df = pd.read_csv(darshan_file + \".dxt.log\", delimiter='\\t', comment='#',\n",
    "                 names=[\"Module\", \"Rank\", \"IOType\", \"Segment\", \"Offset\",\n",
    "                        \"Length\", \"Start\", \"End\"])\n",
    "# Add information about the added files\n",
    "df[\"File\"] = get_accessed_files(darshan_file + \".dxt.log\")\n",
    "df[\"Offset_end\"] = df[\"Offset\"] + df[\"Length\"]\n",
    "# Filter out entries with length 0\n",
    "df = df[df.Length > 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extarct_interval_groups(df, start, end, groupby=[]):\n",
    "    # Sort by the groupby first and within each groupby sort by start time\n",
    "    sort_columns = []\n",
    "    if len(groupby) > 0:\n",
    "        sort_columns += groupby\n",
    "    sort_columns.append(start)\n",
    "    df_temp = df[df[end] - df[start] > 0].sort_values(by=sort_columns)\n",
    "    print(\"Number of entries for the overlap computation:\", len(df_temp))\n",
    "\n",
    "    # Increase the group id if the next entry has the start stricly before the end of the privious segment \n",
    "    criteria = (df_temp[start] < df_temp[end].shift()) & (df_temp[end] >= df_temp[start].shift())\n",
    "    for entry in groupby:\n",
    "        criteria = criteria & (df_temp[entry] == df_temp[entry].shift())\n",
    "    df_temp[\"group\"]=criteria.cumsum()\n",
    "    return df_temp\n",
    "\n",
    "def _extarct_non_overlap_groups(df, start, end, groupby=[]):\n",
    "    # Sort by the groupby first and within each groupby sort by start time\n",
    "    sort_columns = []\n",
    "    if len(groupby) > 0:\n",
    "        sort_columns += groupby\n",
    "    sort_columns.append(start)\n",
    "    df_temp = df[df[end] - df[start] > 0].sort_values(by=sort_columns)\n",
    "    print(\"Number of entries for the overlap computation:\", len(df_temp))\n",
    "\n",
    "    criteria = (df_temp[start] >= df_temp[end].shift()) | (df_temp[end] < df_temp[start].shift())\n",
    "    for entry in groupby:\n",
    "        criteria = criteria | (df_temp[entry] != df_temp[entry].shift())\n",
    "    df_temp[\"group\"]=criteria.cumsum()\n",
    "    return df_temp\n",
    "\n",
    "def percentage_overlap_interval(df, start, end, groupby=[]):\n",
    "    df_temp = _extarct_interval_groups(df, start, end, groupby)\n",
    "    # Percentage of overlapping intervals is defined by the ration between the number of groups and the total entries\n",
    "    return df_temp[\"group\"].max() * 100 / len(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for the overlap computation: 64850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.66769468003084"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all entries that overlap their (start, end) accesses\n",
    "percentage_overlap_interval(df, \"Start\", \"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather features according to ANL list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the aggregated logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288907.5160659403\n",
      "1073.1952712333361\n"
     ]
    }
   ],
   "source": [
    "type_op = [\"READ\", \"WRITE\"]\n",
    "minperf = {}\n",
    "for op in type_op:\n",
    "    # the temp dataframes will have one entry per file\n",
    "    temp_time = df_agg[(df_agg.Counter == \"POSIX_F_MAX_%s_TIME\" %(op)) & (df_agg.Value > 0)]\n",
    "    temp_size = df_agg[(df_agg.Counter == \"POSIX_MAX_%s_TIME_SIZE\" %(op)) & (df_agg.Value > 0)]\n",
    "\n",
    "    fast_recordid = temp_time['RecordID'].unique()\n",
    "    perf = {}\n",
    "    for record in fast_recordid:\n",
    "        # time / size\n",
    "        time = temp_time[(temp_time.RecordID == record)][\"Value\"].values[0]\n",
    "        size = temp_size[(temp_size.RecordID == record)][\"Value\"].values[0]\n",
    "        if record not in perf:\n",
    "            perf[record] = size / time\n",
    "        if size / time < perf[record]:\n",
    "            perf[record] = size / time\n",
    "    minperf[op] = min([perf[i] for i in perf])\n",
    "    print(minperf[op])\n",
    "    \n",
    "feature_list[\"POSIX_RAW_agg_perf_by_slowest\"] = min(minperf[i] for i in minperf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_op = [\"READ\", \"WRITTEN\"]\n",
    "feature_list[\"POSIX_RAW_total_bytes\"] = 0\n",
    "for op in type_op:\n",
    "    feature_list[\"POSIX_RAW_total_bytes\"] += df_agg[(df_agg.Counter == \"POSIX_BYTES_%s\" %(op)) &\n",
    "                                                    (df_agg.Value > 0)][\"Value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list[\"Total_procs\"] = int(metadata[\"nprocs\"][0])\n",
    "feature_list[\"RAW_runtime\"] = int(metadata[\"run time\"][0])\n",
    "feature_list[\"users\"] = len(metadata[\"uid\"][0].split(\" \"))\n",
    "feature_list[\"apps\"] = len(metadata[\"jobid\"][0].split(\" \"))\n",
    "feature_list[\"apps_short\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list[\"POSIX_RAW_OPENS\"] = df_agg[df_agg.Counter == \"POSIX_OPENS\"][\"Value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_op = ['READS', 'WRITES', 'OPENS', 'SEEKS', 'STATS', 'MMAPS', 'SYNCS']\n",
    "total_ops = 0\n",
    "for op in type_op:\n",
    "    total_ops += df_agg[(df_agg.Counter == \"POSIX_\" + op) & (df_agg.Value > 0)][\"Value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list[\"POSIX_RAW_total_accesses\"] = total_ops\n",
    "feature_list[\"POSIX_RAW_total_files\"] = len(df_agg[df_agg.Value > 0][\"FileName\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ops = [\"READ\", \"WRITTEN\"]\n",
    "for op in type_ops:\n",
    "    feature_list[\"POSIX_BYTES_%s_PERC\" %(op)] = df_agg[df_agg.Counter == \"POSIX_BYTES_%s\" %(op)][\"Value\"].sum() * 100 /\\\n",
    "                                                feature_list[\"POSIX_RAW_total_bytes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared files are the ones accessed by more than one rank\n",
    "temp = []\n",
    "for _, group in df_agg[df_agg.Value > 0].groupby('FileName'):\n",
    "    temp.append(len(group.Rank.unique()))\n",
    "feature_list[\"POSIX_unique_files_perc\"] = len([i for i in temp if i == 1]) * 100 / feature_list[\"POSIX_RAW_total_files\"]\n",
    "feature_list[\"POSIX_shared_files_perc\"] = len([i for i in temp if i > 1]) * 100 / feature_list[\"POSIX_RAW_total_files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only files are the ones that appear in only READ operations\n",
    "write_set = set(df_agg[(df_agg.Value > 0) & (df_agg.Counter.str.contains(\"WRITE|WRITTEN\"))][\"FileName\"].unique())\n",
    "read_set = set(df_agg[(df_agg.Value > 0) & (df_agg.Counter.str.contains(\"READ\"))][\"FileName\"].unique())\n",
    "\n",
    "feature_list[\"POSIX_read_only_files_perc\"] = len(read_set - write_set) * 100 / len(read_set | write_set)\n",
    "feature_list[\"POSIX_read_write_files_perc\"] = len(write_set & read_set) * 100 / len(read_set | write_set)\n",
    "feature_list[\"POSIX_write_only_files_perc\"] = len(write_set - read_set) * 100 / len(read_set | write_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage is defined as sum of each counter over total number of accesses\n",
    "type_op = [\"POSIX_WRITES_PERC\", \"POSIX_RW_SWITCHES_PERC\", \"POSIX_READS_PERC\",\n",
    "                \"POSIX_FILE_NOT_ALIGNED_PERC\", \"POSIX_MEM_NOT_ALIGNED_PERC\",\n",
    "                \"POSIX_SIZE_READ_0_100_PERC\", \"POSIX_SIZE_READ_100_1K_PERC\",\n",
    "                \"POSIX_SIZE_READ_1K_10K_PERC\", \"POSIX_SIZE_READ_10K_100K_PERC\",\n",
    "                \"POSIX_SIZE_READ_100K_1M_PERC\", \"POSIX_SIZE_READ_1M_4M_PERC\",\n",
    "                \"POSIX_SIZE_READ_4M_10M_PERC\", \"POSIX_SIZE_READ_10M_100M_PERC\",\n",
    "                \"POSIX_SIZE_READ_100M_1G_PERC\", \"POSIX_SIZE_READ_1G_PLUS_PERC\",\n",
    "                \"POSIX_SIZE_WRITE_0_100_PERC\", \"POSIX_SIZE_WRITE_100_1K_PERC\",\n",
    "                \"POSIX_SIZE_WRITE_1K_10K_PERC\", \"POSIX_SIZE_WRITE_10K_100K_PERC\",\n",
    "                \"POSIX_SIZE_WRITE_100K_1M_PERC\", \"POSIX_SIZE_WRITE_1M_4M_PERC\",\n",
    "                \"POSIX_SIZE_WRITE_4M_10M_PERC\", \"POSIX_SIZE_WRITE_10M_100M_PERC\",\n",
    "                \"POSIX_SIZE_WRITE_100M_1G_PERC\", \"POSIX_SIZE_WRITE_1G_PLUS_PERC\",\n",
    "                \"POSIX_ACCESS1_COUNT_PERC\", \"POSIX_ACCESS2_COUNT_PERC\",\n",
    "                \"POSIX_ACCESS3_COUNT_PERC\", \"POSIX_ACCESS4_COUNT_PERC\"]\n",
    "for op_perc in type_op:\n",
    "    op = op_perc[:-5]\n",
    "    feature_list[op_perc] = df_agg[(df_agg.Value > 0) & (df_agg.Counter == op)][\"Value\"].sum() * \\\n",
    "                            100 / feature_list[\"POSIX_RAW_total_accesses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage is defined by sum of each conter over total writes or total reads \n",
    "type_op = [\"POSIX_SEQ_READS_PERC\", \"POSIX_SEQ_WRITES_PERC\",\n",
    "            \"POSIX_CONSEC_READS_PERC\", \"POSIX_CONSEC_WRITES_PERC\"]\n",
    "for op_perc in type_op:\n",
    "    op = op_perc[:-5]\n",
    "    total_access_type = df_agg[df_agg.Counter == \"POSIX_WRITES\"][\"Value\"].sum()\n",
    "    if \"READ\" in op:\n",
    "        total_access_type = df_agg[df_agg.Counter == \"POSIX_READS\"][\"Value\"].sum()\n",
    "    feature_list[op_perc] = df_agg[(df_agg.Value > 0) & (df_agg.Counter == op)][\"Value\"].sum() * \\\n",
    "                            100 / total_access_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = [\"POSIX_LOG10_agg_perf_by_slowest\", \"POSIX_LOG10_MODE\",\n",
    "    \"POSIX_LOG10_total_bytes\", \"LOG10_nprocs\", \"POSIX_LOG10_SEEKS\",\n",
    "    \"LOG10_runtime\", \"POSIX_LOG10_STATS\", \"POSIX_LOG10_MMAPS\",\n",
    "    \"POSIX_LOG10_FSYNCS\", \"POSIX_LOG10_MEM_ALIGNMENT\",\n",
    "    \"POSIX_LOG10_FILE_ALIGNMENT\", \"POSIX_LOG10_OPENS\",\n",
    "    \"POSIX_LOG10_total_accesses\", \"POSIX_LOG10_total_files\"]\n",
    "for i in extra:\n",
    "    feature_list[i] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the DXT logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the information in the aggregated and the DXT logs are consistent\n",
    "filelist = df[\"File\"].unique()\n",
    "for i in filelist:\n",
    "    # read\n",
    "    dxt = df[(df.File == i) & (df.IOType == \"read\") & (df.Module.str.contains(\"POSIX\"))][\"Length\"].sum()\n",
    "    agg = df_agg[(df_agg.FileName.str.contains(i)) & (df_agg.Counter == \"POSIX_BYTES_READ\")][\"Value\"].sum()\n",
    "    if dxt != agg:\n",
    "        print(\"READ\", i, dxt, agg)\n",
    "    # write\n",
    "    dxt = df[(df.File == i) & (df.IOType == \"write\") & (df.Module.str.contains(\"POSIX\"))][\"Length\"].sum()\n",
    "    agg = df_agg[(df_agg.FileName == i) & (df_agg.Counter == \"POSIX_BYTES_WRITTEN\")][\"Value\"].sum()\n",
    "    if dxt != agg:\n",
    "        print(\"WRITE\", i, dxt, agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for the overlap computation: 229115\n"
     ]
    }
   ],
   "source": [
    "# overlapping intervals between start offset to end offset groupby each file\n",
    "feature_list[\"POSIX_shared_bytes_perc\"] = percentage_overlap_interval(df, \"Offset\", \"Offset_end\", [\"File\"])\n",
    "feature_list[\"POSIX_unique_bytes_perc\"] = 100 - feature_list[\"POSIX_shared_bytes_perc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RW_only_segments(df):\n",
    "    df_temp = _extarct_non_overlap_groups(df, \"Offset\", \"Offset_end\", groupby=[\"File\"])\n",
    "    a = df_temp.groupby('group')['IOType'].unique()\n",
    "    return (len([i for i in a if len(i)==2]),\n",
    "            len([i for i in a if len(i)==1 and i[0]=='read']),\n",
    "            len([i for i in a if len(i)==1 and i[0]=='write']))\n",
    "\n",
    "segments = RW_only_segments(df)\n",
    "feature_list[\"POSIX_read_write_bytes_perc\"] = segments[0] * 100 / sum(segments)\n",
    "feature_list[\"POSIX_read_only_bytes_perc\"] = segments[1] * 100 / sum(segments)\n",
    "feature_list[\"POSIX_write_only_bytes_perc\"] = segments[2] * 100 / sum(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW 0 2732\n",
      "RAR 2728 2732\n",
      "WAR 0 226383\n",
      "WAW 226371 226383\n"
     ]
    }
   ],
   "source": [
    "# Read after write (percentage of reads after write to total reads)\n",
    "# subgroup is true if consecutive entries belong to the same file and the two consecutive entries are write / read\n",
    "df['subgroup'] = (df['IOType'] == \"write\") & (df['IOType'].shift(1) == \"read\") & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"READ_after_WRITE\"] = len(df[df.subgroup == True]) * 100 / len(df[df.IOType == \"read\"])\n",
    "print(\"RAW\", len(df[df.subgroup == True]), len(df[df.IOType == \"read\"]))\n",
    "\n",
    "df['subgroup'] = (df['IOType'] == \"read\") & (df['IOType'].shift(1) == \"read\") & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"READ_after_READ\"] = len(df[df.subgroup == True]) * 100 / len(df[df.IOType == \"read\"])\n",
    "print(\"RAR\", len(df[df.subgroup == True]), len(df[df.IOType == \"read\"]))\n",
    "\n",
    "\n",
    "# Write after read (percentage of writes after read to total writes)\n",
    "# subgroup is true if consecutive entries belong to the same file and the two consecutive entries are read / write\n",
    "df['subgroup'] = (df['IOType'] == \"read\") & (df['IOType'].shift(1) == \"write\") & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"WRITE_after_READ\"] = len(df[df.subgroup == True]) * 100 / len(df[df.IOType == \"write\"])\n",
    "print(\"WAR\", len(df[df.subgroup == True]), len(df[df.IOType == \"write\"]))\n",
    "\n",
    "\n",
    "df['subgroup'] = (df['IOType'] == \"write\") & (df['IOType'].shift(1) == \"write\") & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"WRITE_after_WRITE\"] = len(df[df.subgroup == True]) * 100 / len(df[df.IOType == \"write\"])\n",
    "print(\"WAW\", len(df[df.subgroup == True]), len(df[df.IOType == \"write\"]))\n",
    "\n",
    "# RAW and RAR to not equal to 100 because the first read of each file is not counted toward either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consecutive memory accesses to the same file by the same rank\n",
    "df['subgroup'] = (df['Rank'] == df['Rank'].shift(1)) & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"Rank_consecutive_RAW\"] = len(df[df.subgroup == True]) * 100 / feature_list[\"POSIX_RAW_total_accesses\"]\n",
    "\n",
    "# consecutive memory accesses to the same file by the different ranks\n",
    "df['subgroup'] = (df['Rank'] != df['Rank'].shift(1)) & (df['File'] == df['File'].shift(1))\n",
    "feature_list[\"Rank_switched_RAW\"] = len(df[df.subgroup == True]) * 100 / feature_list[\"POSIX_RAW_total_accesses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for the overlap computation: 64850\n",
      "Number of entries for the overlap computation: 211\n",
      "Number of entries for the overlap computation: 64639\n"
     ]
    }
   ],
   "source": [
    "feature_list[\"Perc_overlap_access\"] = percentage_overlap_interval(df, \"Start\", \"End\")\n",
    "feature_list[\"READ_perc_overlap\"] = percentage_overlap_interval(df[df.IOType==\"read\"], \"Start\", \"End\")\n",
    "feature_list[\"WRITE_perc_overlap\"] = percentage_overlap_interval(df[df.IOType==\"write\"], \"Start\", \"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for the overlap computation: 229115\n",
      "Number of entries for the overlap computation: 64850\n"
     ]
    }
   ],
   "source": [
    "feature_list[\"RAW_nprocs\"] = len(df[\"Rank\"].unique())\n",
    "feature_list[\"Perc_ranks_READS\"] = len(df[df.IOType == \"read\"][\"Rank\"].unique()) * 100 / feature_list[\"RAW_nprocs\"]\n",
    "feature_list[\"Perc_ranks_WRITES\"] = len(df[df.IOType == \"write\"][\"Rank\"].unique()) * 100 / feature_list[\"RAW_nprocs\"]\n",
    "\n",
    "# ranks doing only read, only write\n",
    "temp = df.groupby('Rank')['IOType'].unique()\n",
    "feature_list[\"Ranks_read_write\"] = len([i for i in temp if len(i)==2])\n",
    "feature_list[\"Ranks_read_only\"] = len([i for i in temp if len(i)==1 and i[0]==\"read\"])\n",
    "feature_list[\"Ranks_write_only\"] = len([i for i in temp if len(i)==1 and i[0]==\"write\"])\n",
    "\n",
    "# percentage files writen by ony one rank\n",
    "temp = df.groupby('File')['Rank'].unique()\n",
    "feature_list[\"File_one_rank\"] = len([i for i in temp if len(i)==1])\n",
    "feature_list[\"File_multiple_ranks\"] = len([i for i in temp if len(i)>1])\n",
    "\n",
    "# percentage segments writen by ony one rank\n",
    "temp = _extarct_non_overlap_groups(df, \"Offset\", \"Offset_end\", groupby=[\"File\"])\n",
    "a = temp.groupby('group')['Rank'].unique()\n",
    "# (pd.DataFrame.from_records(a.values.tolist()).stack().value_counts())\n",
    "feature_list[\"Segments_one_rank\"] = len([i for i in a if len(i)==1])\n",
    "feature_list[\"Segments_one_rank\"] = len([i for i in a if len(i)>1])\n",
    "\n",
    "# one_rank_only (access done by only one rank at the time)\n",
    "temp = _extarct_non_overlap_groups(df, \"Start\", \"End\")\n",
    "a = temp.groupby('group')['Rank'].unique()\n",
    "feature_list[\"Accesses_one_rank\"] = len([i for i in a if len(i)==1])\n",
    "feature_list[\"Accesses_simultaneous_ranks\"] = len([i for i in a if len(i)>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the features into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the feature list in a csv file\n",
    "write_header = True\n",
    "if os.path.isfile('feature_list.csv'):\n",
    "    write_header = False\n",
    "with open('feature_list.csv', 'a') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=list(feature_list.keys()))\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerows([feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSIX_RAW_agg_perf_by_slowest': 1073.1952712333361,\n",
       " 'POSIX_RAW_total_bytes': 38031035998.0,\n",
       " 'Total_procs': 224,\n",
       " 'RAW_runtime': 177,\n",
       " 'users': 1,\n",
       " 'apps': 1,\n",
       " 'apps_short': 0,\n",
       " 'POSIX_RAW_OPENS': 469.0,\n",
       " 'POSIX_RAW_total_accesses': 230064.0,\n",
       " 'POSIX_RAW_total_files': 468,\n",
       " 'POSIX_BYTES_READ_PERC': 0.05875323512400521,\n",
       " 'POSIX_BYTES_WRITTEN_PERC': 99.941246764876,\n",
       " 'POSIX_unique_files_perc': 100.0,\n",
       " 'POSIX_shared_files_perc': 0.0,\n",
       " 'POSIX_read_only_files_perc': 21.05263157894737,\n",
       " 'POSIX_read_write_files_perc': 10.526315789473685,\n",
       " 'POSIX_write_only_files_perc': 68.42105263157895,\n",
       " 'POSIX_WRITES_PERC': 98.40001043187982,\n",
       " 'POSIX_RW_SWITCHES_PERC': 0.0,\n",
       " 'POSIX_READS_PERC': 1.1909729466583212,\n",
       " 'POSIX_FILE_NOT_ALIGNED_PERC': 99.5818554836915,\n",
       " 'POSIX_MEM_NOT_ALIGNED_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_0_100_PERC': 0.0034772932749148064,\n",
       " 'POSIX_SIZE_READ_100_1K_PERC': 0.0017386466374574032,\n",
       " 'POSIX_SIZE_READ_1K_10K_PERC': 1.1857570067459489,\n",
       " 'POSIX_SIZE_READ_10K_100K_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_100K_1M_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_1M_4M_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_4M_10M_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_10M_100M_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_100M_1G_PERC': 0.0,\n",
       " 'POSIX_SIZE_READ_1G_PLUS_PERC': 0.0,\n",
       " 'POSIX_SIZE_WRITE_0_100_PERC': 0.43509632102371515,\n",
       " 'POSIX_SIZE_WRITE_100_1K_PERC': 0.0008693233187287016,\n",
       " 'POSIX_SIZE_WRITE_1K_10K_PERC': 0.16473676889908895,\n",
       " 'POSIX_SIZE_WRITE_10K_100K_PERC': 0.0004346616593643508,\n",
       " 'POSIX_SIZE_WRITE_100K_1M_PERC': 97.79887335697893,\n",
       " 'POSIX_SIZE_WRITE_1M_4M_PERC': 0.0,\n",
       " 'POSIX_SIZE_WRITE_4M_10M_PERC': 0.0,\n",
       " 'POSIX_SIZE_WRITE_10M_100M_PERC': 0.0,\n",
       " 'POSIX_SIZE_WRITE_100M_1G_PERC': 0.0,\n",
       " 'POSIX_SIZE_WRITE_1G_PLUS_PERC': 0.0,\n",
       " 'POSIX_ACCESS1_COUNT_PERC': 87.41915293135823,\n",
       " 'POSIX_ACCESS2_COUNT_PERC': 8.603258223798596,\n",
       " 'POSIX_ACCESS3_COUNT_PERC': 2.3523889004798666,\n",
       " 'POSIX_ACCESS4_COUNT_PERC': 0.7597885805688852,\n",
       " 'POSIX_SEQ_READS_PERC': 99.67153284671532,\n",
       " 'POSIX_SEQ_WRITES_PERC': 99.99381579005491,\n",
       " 'POSIX_CONSEC_READS_PERC': 99.67153284671532,\n",
       " 'POSIX_CONSEC_WRITES_PERC': 99.99381579005491,\n",
       " 'POSIX_LOG10_agg_perf_by_slowest': -1,\n",
       " 'POSIX_LOG10_MODE': -1,\n",
       " 'POSIX_LOG10_total_bytes': -1,\n",
       " 'LOG10_nprocs': -1,\n",
       " 'POSIX_LOG10_SEEKS': -1,\n",
       " 'LOG10_runtime': -1,\n",
       " 'POSIX_LOG10_STATS': -1,\n",
       " 'POSIX_LOG10_MMAPS': -1,\n",
       " 'POSIX_LOG10_FSYNCS': -1,\n",
       " 'POSIX_LOG10_MEM_ALIGNMENT': -1,\n",
       " 'POSIX_LOG10_FILE_ALIGNMENT': -1,\n",
       " 'POSIX_LOG10_OPENS': -1,\n",
       " 'POSIX_LOG10_total_accesses': -1,\n",
       " 'POSIX_LOG10_total_files': -1,\n",
       " 'POSIX_shared_bytes_perc': 0.532483687231303,\n",
       " 'POSIX_unique_bytes_perc': 99.4675163127687,\n",
       " 'POSIX_read_write_bytes_perc': 0.0,\n",
       " 'POSIX_read_only_bytes_perc': 0.6643410342482283,\n",
       " 'POSIX_write_only_bytes_perc': 99.33565896575178,\n",
       " 'READ_after_WRITE': 0.0,\n",
       " 'READ_after_READ': 99.85358711566617,\n",
       " 'WRITE_after_READ': 0.0,\n",
       " 'WRITE_after_WRITE': 99.99469924861849,\n",
       " 'Rank_consecutive_RAW': 99.5805514987134,\n",
       " 'Rank_switched_RAW': 0.0,\n",
       " 'Perc_overlap_access': 30.66769468003084,\n",
       " 'READ_perc_overlap': 0.0,\n",
       " 'WRITE_perc_overlap': 30.806479060629034,\n",
       " 'RAW_nprocs': 6,\n",
       " 'Perc_ranks_READS': 16.666666666666668,\n",
       " 'Perc_ranks_WRITES': 100.0,\n",
       " 'Ranks_read_write': 1,\n",
       " 'Ranks_read_only': 0,\n",
       " 'Ranks_write_only': 5,\n",
       " 'File_one_rank': 16,\n",
       " 'File_multiple_ranks': 0,\n",
       " 'Segments_one_rank': 0,\n",
       " 'Accesses_one_rank': 30700,\n",
       " 'Accesses_simultaneous_ranks': 14262}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
